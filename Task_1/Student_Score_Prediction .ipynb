{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By: Mohd Yusuf\n",
    "### Prediction using Supervised ML\n",
    "### Task 1\n",
    "\n",
    "### TSF  GRIP JUNE21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset URL:\"http://bit.ly/w-data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NumPy is a Python library used for working with arrays and has functions for working in domain of linear algebra, fourier transform, and matrices.\n",
    "\n",
    "\n",
    "#### Pandas is a software library written for the Python programming language for data manipulation and analysis\n",
    "\n",
    "\n",
    "#### Matplotlib is a Ploting Library \n",
    "\n",
    "#### Inline is used here to store the plots in the notebook itself \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn is a library in Python that provides many unsupervised and supervised learning algorithms. It’s built upon NumPy, pandas, and Matplotlib!\n",
    "\n",
    "The functionality that scikit-learn provides include:\n",
    "\n",
    "Regression, including Linear and Logistic Regression\n",
    "Classification, including K-Nearest Neighbors\n",
    "Clustering, including K-Means and K-Means++\n",
    "Model selection\n",
    "Preprocessing, including Min-Max Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring and Understanding our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = \"http://bit.ly/w-data\"\n",
    "data = pd.read_csv(url)\n",
    "print(\"Data imported successfully\")\n",
    "\n",
    "data.head() #to see first 5 rows of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape #to find the shape of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i.e. we have 25 entries and 2 columns, the first column is Hours (Independent Variable) and Score (Depending Variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe() #data description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " data.info()  #info of dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " \n",
    " ### Visualising our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution of scores\n",
    "\n",
    "x = data.iloc[ : , :-1]\n",
    "y = data.iloc[ : ,-1]\n",
    "plt.plot(x,y,'bo')  \n",
    "\n",
    "plt.title('Hours vs Percentage Score')  \n",
    "plt.xlabel('Hours Studied')  \n",
    "plt.ylabel('Percentage Score')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.corr() #corr() is used to find the pairwise correlation of all columns in the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can clearly see that there is a positive linear relation between the number of hours studied and percentage of score.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As we have already splitted our data into attributes(input variable) and labels(output variable) as x and y . We will now split the data into training and testing sets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train,x_test,y_train,y_test= train_test_split(x,y,test_size=0.2,random_state=2)\n",
    "# Splitting the Dataset into 80:20 ( 80% data for Training and 20% data for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression  \n",
    "reg = LinearRegression()  \n",
    "reg.fit(x_train, y_train) \n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the regression line\n",
    "line = reg.coef_*x+reg.intercept_\n",
    "\n",
    "# Plotting for the test data\n",
    "plt.scatter(x, y,color='green')\n",
    "plt.plot(x, line);\n",
    "plt.title('Hours vs Percentage Score')  \n",
    "plt.xlabel('Hours Studied')  \n",
    "plt.ylabel('Percentage Score')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Score: \",reg.score(x_train,y_train)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions\n",
    "Now that we have trained our algorithm with good score, it's time to make some predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=reg.predict(x_test)\n",
    "print(\"Predicted Values of our Testing data is : \")\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comparing Actual Data and Predicated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing the actual y_test set and predicted y_pred data we get\n",
    "df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred, 'Difference/Error': y_test - y_pred})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Evaluation \n",
    "For Evaluation of the Regression Model Sklearn module provide many metrics. We are going to use these metrics to evaluate our model.\n",
    "\n",
    "-  Mean absolute error : It measures the average magnitude of the errors in a set of predictions, without considering their direction.\n",
    "\n",
    "-  Mean squared error : It measures the average of the squares of the errors—that is, the average squared difference between the estimated values and the actual value. \n",
    "\n",
    "-  Root mean squared error : RMSE is a quadratic scoring rule that also measures the average magnitude of the error. It’s the square root of the average of squared differences between prediction and actual observation.\n",
    "\n",
    "- R2-score : It provides an indication of goodness of fit and therefore a measure of how well unseen samples are likely to be predicted by the model, through the proportion of explained variance.Best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a R² score of 0.0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_absolute_error\n",
    "print(\"Mean Absolute Error : \",mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_squared_error ( MSE Value)\n",
    "print(\"Mean Squared Error ( MSE Value) :\",mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_squared_error ( RMSE Value)\n",
    "print(\"Mean Squared Error ( RMSE Value) :\",mean_squared_error(y_test, y_pred, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#R2_Score\n",
    "print(\"Prediction Score : \", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What will be predicted score if a student studies for 9.25 hrs/ day?\n",
    "So well answer is :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hours = [[9.25]]\n",
    "pred = reg.predict(hours)\n",
    "print(\"Score obtained by the student if he studies for 9.25 hours/day is : \",pred[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good score perhaps!\n",
    "Keep Learning :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
